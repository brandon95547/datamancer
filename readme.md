### **ğŸ“ Datamancer**
**Advanced Web Scraping & Data Extraction for Node.js**

[![Node.js](https://img.shields.io/badge/Node.js-v16%2B-green)](https://nodejs.org/)
Author: **Synexis AI** | [Website](https://synexisai.com)

---

## **ğŸ“Œ Overview**
**Datamancer** is a powerful, flexible, and efficient web scraping tool built with **Node.js** and **Puppeteer**. It enables developers to automate data extraction, process web pages dynamically, and save structured content for further analysis.

### **âœ¨ Features**
âœ… **Headless Browsing with Puppeteer** â€“ Automates interaction with web pages  
âœ… **Efficient Asset & Data Scraping** â€“ Extracts images, scripts, and structured data  
âœ… **Customizable Extraction Rules** â€“ Adapt scraping logic to any website  
âœ… **Handles Dynamic Content** â€“ Supports JavaScript-heavy websites  
âœ… **Concurrent Downloading** â€“ Faster scraping with parallel requests  
âœ… **Output in JSON, CSV, or Database** â€“ Flexible data storage options  

---

## **ğŸš€ Installation**
Make sure you have **Node.js (16+)** installed. Then, install Datamancer with:  

```sh
git clone https://github.com/synexisai/datamancer.git
cd datamancer
npm install
```

---

## **ğŸ“‚ Project Structure**
```
datamancer/
â”‚â”€â”€ scrape.js              # Scraper script (uses environment variable for URL)
â”‚â”€â”€ temp/                  # Scraped data storage
â”‚â”€â”€ package.json           # Node.js dependencies
â”‚â”€â”€ README.md              # Project documentation
```

---

## **ğŸ› ï¸ Usage**
### **1âƒ£ Basic Web Scraping**
To start scraping a webpage, set the URL via an environment variable and run:

```sh
cross-env TARGET_URL="https://example.com" node scrape.js
```

Alternatively, without `cross-env`:

On macOS/Linux:
```sh
TARGET_URL="https://example.com" node scrape.js
```

On Windows (cmd):
```cmd
set TARGET_URL=https://example.com && node scrape.js
```

On Windows (PowerShell):
```powershell
$env:TARGET_URL="https://example.com"; node scrape.js
```

### **2âƒ£ Extract Specific Data**
Modify `scraper.js` to extract specific elements like:
```js
const data = await page.evaluate(() => {
    return Array.from(document.querySelectorAll('.article-title'))
        .map(el => el.innerText);
});
```

### **3âƒ£ Save Data in JSON**
Run:
```sh
node src/index.js --url "https://example.com" --output "data.json"
```

---

## **âš™ï¸ Configuration**
Modify the `config/settings.json` file:
```json
{
    "headless": true,
    "outputFormat": "json",
    "maxPages": 10
}
```

---

## **ğŸ“ License**
This project is licensed under the **MIT License**.

---

## **ğŸ“§ Contact**
**Synexis AI**  
ğŸŒ Website: [synexisai.com](https://synexisai.com)  
ğŸ“§ Email: support@synexisai.com  

---

### **ğŸš€ Happy Scraping!**

